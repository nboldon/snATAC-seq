

###############################################
###############################################
## CLUSTER-SPECIFIC PEAK ANALYSIS BY SAMPLE
## Using Existing PeakMatrix 
###############################################
###############################################

library(ArchR)
library(ggplot2)
library(dplyr)


###############################################
## 1. SETUP: Rename samples and create identifiers
###############################################

# Get and rename samples
sample <- projP_3$Sample
sample <- gsub("cortex_fresh_v1", "sample1", sample)
sample <- gsub("cortex_v1-1_chromx", "sample2", sample)
sample <- gsub("cortex_v2_chromx", "sample3", sample)
sample <- gsub("cortex_v2_cont", "sample4", sample)

# Add to project
projP_3$sample <- sample
table(projP_3$sample)

# Create combined sample_cluster identifier
projP_3$sample_cluster <- paste0(projP_3$sample, "_", projP_3$Clusters)
table(projP_3$sample_cluster)

# Get all unique clusters
all_clusters <- unique(projP_3$Clusters)
print(all_clusters)

###############################################
## 2. VERIFY EXISTING PEAK MATRIX
###############################################

# Check what matrices are available
print("Available matrices:")
print(getAvailableMatrices(projP_3))

# Verify PeakMatrix exists
if(!"PeakMatrix" %in% getAvailableMatrices(projP_3)) {
  stop("PeakMatrix not found! Please run addPeakMatrix() first.")
}

print("\nUsing existing PeakMatrix for sample-cluster comparisons")

# Get peak information
peakSet <- getPeakSet(projP_3)
print(paste("Total peaks in dataset:", length(peakSet)))


###############################################
## 3. HELPER FUNCTIONS
###############################################

# Function to find common clusters between two samples
get_common_clusters <- function(sample1_name, sample2_name) {
  sample1_combinations <- unique(projP_3$sample_cluster[projP_3$sample == sample1_name])
  sample2_combinations <- unique(projP_3$sample_cluster[projP_3$sample == sample2_name])
  
  sample1_clusters <- gsub(paste0(sample1_name, "_"), "", sample1_combinations)
  sample2_clusters <- gsub(paste0(sample2_name, "_"), "", sample2_combinations)
  
  common <- intersect(sample1_clusters, sample2_clusters)
  return(common)
}


###############################################
## 4. PEAK COMPARISON FUNCTION
###############################################

# Close any open devices
while(dev.cur() > 1) dev.off()

# Function to perform cluster-specific peak comparison
compare_peaks_by_cluster <- function(sample1_name, sample2_name, cluster_name) {
  
  print(paste("Analyzing peaks:", sample1_name, "vs", sample2_name, "in", cluster_name))
  
  # Subset to specific cluster
  clusterSubset <- projP_3[projP_3$Clusters %in% cluster_name]
  
  # Check if both samples exist in this cluster
  samples_in_cluster <- unique(clusterSubset$sample)
  if(!all(c(sample1_name, sample2_name) %in% samples_in_cluster)) {
    print(paste("  Skipping - not all samples present in", cluster_name))
    return(NULL)
  }
  
  # Check cell counts
  n_s1 <- sum(clusterSubset$sample == sample1_name)
  n_s2 <- sum(clusterSubset$sample == sample2_name)
  print(paste("  Cells:", sample1_name, "=", n_s1, ",", sample2_name, "=", n_s2))
  
  if(n_s1 < 25 || n_s2 < 25) {
    print(paste("  Skipping - insufficient cells (need ≥25 per sample)"))
    return(NULL)
  }
  
  # Get marker peaks using existing PeakMatrix
  markerPeaks <- getMarkerFeatures(
    ArchRProj = clusterSubset,
    useMatrix = "PeakMatrix",
    groupBy = "sample",
    bias = c("TSSEnrichment", "log10(nFrags)"),
    testMethod = "wilcoxon",
    useGroups = sample1_name,
    bgdGroups = sample2_name
  )
  
  # Extract results with conservative cutoff
  markerList <- getMarkers(markerPeaks, cutOff = "FDR <= 0.01 & abs(Log2FC) >= 1.25")
  
  # Save CSV if markers found
  if(sample1_name %in% names(markerList)) {
    markers <- markerList[[sample1_name]]
    if(nrow(markers) > 0) {
      filename <- paste0(sample1_name, "_vs_", sample2_name, "_", cluster_name, "_peaks.csv")
      write.csv(markers, file = filename, row.names = TRUE)
      print(paste("  Saved", nrow(markers), "significant peaks to", filename))
      
      # Create volcano plot
      create_peak_volcano(markerPeaks, sample1_name, sample2_name, cluster_name, markers)
      
      return(markers)
    }
  }
  
  print(paste("  No significant peaks found"))
  return(NULL)
}

# Function to create volcano plot for peaks
create_peak_volcano <- function(markerPeaks, s1, s2, cluster, sig_markers) {
  
  # Get all results for volcano plot
  all_results <- getMarkers(markerPeaks, cutOff = "FDR <= 1")
  
  if(s1 %in% names(all_results)) {
    volcano_data <- all_results[[s1]]
    
    if(nrow(volcano_data) > 10) {
      
      # Add significance category
      volcano_data$Significant <- ifelse(
        volcano_data$FDR <= 0.1 & abs(volcano_data$Log2FC) >= 0.5,
        "Significant",
        "Not Significant"
      )
      
      # Create plot
      pv <- ggplot(volcano_data, aes(x = Log2FC, y = -log10(FDR), color = Significant)) +
        geom_point(alpha = 0.6, size = 1.5) +
        scale_color_manual(values = c("Not Significant" = "grey50", "Significant" = "red")) +
        geom_hline(yintercept = -log10(0.1), linetype = "dashed", color = "blue", linewidth = 0.5) +
        geom_vline(xintercept = c(-0.5, 0.5), linetype = "dashed", color = "blue", linewidth = 0.5) +
        labs(
          title = paste0(s1, " vs ", s2, " - ", cluster, " (Peaks)"),
          x = "Log2 Fold Change",
          y = "-Log10(FDR)",
          subtitle = paste0(nrow(sig_markers), " significant peaks (FDR≤0.01, |Log2FC|≥1.25)")
        ) +
        theme_bw() +
        theme(
          legend.position = "top",
          plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
          plot.subtitle = element_text(hjust = 0.5, size = 10)
        )
      
      # Save plot
      plots_dir <- paste0(getOutputDirectory(projP_3), "/Plots/")
      if(!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE)
      
      tryCatch({
        ggsave(
          filename = paste0(plots_dir, s1, "_vs_", s2, "_", cluster, "_Peaks_Volcano_2025-10-09.pdf"),
          plot = pv,
          width = 6,
          height = 5,
          device = "pdf"
        )
        print(paste("  Volcano plot saved for", cluster))
      }, error = function(e) {
        print(paste("  Error saving volcano plot:", e$message))
      }, finally = {
        while(dev.cur() > 1) dev.off()
      })
    }
  }
}


###############################################
## 5. RUN ALL PAIRWISE COMPARISONS
###############################################

# Define all sample pairs
sample_pairs <- list(
  c("sample1", "sample2"),
  c("sample1", "sample3"),
  c("sample1", "sample4"),
  c("sample2", "sample3"),
  c("sample2", "sample4"),
  c("sample3", "sample4")
)

# Store results
all_peak_results <- list()

# Loop through all pairs and clusters
for(pair in sample_pairs) {
  s1 <- pair[1]
  s2 <- pair[2]
  
  print(paste("\n=== Comparing", s1, "vs", s2, "==="))
  
  common_clusters <- get_common_clusters(s1, s2)
  print(paste("Common clusters:", paste(common_clusters, collapse=", ")))
  
  if(length(common_clusters) > 0) {
    for(cluster in common_clusters) {
      result <- compare_peaks_by_cluster(s1, s2, cluster)
      if(!is.null(result)) {
        all_peak_results[[paste(s1, s2, cluster, sep="_")]] <- result
      }
    }
  }
}

# Final cleanup
while(dev.cur() > 1) dev.off()


###############################################
## 6. COMBINE RESULTS BY CLUSTER
###############################################

print("\n=== Combining results by cluster ===")

for(cluster in all_clusters) {
  
  print(paste("Combining peak data for", cluster))
  cluster_data_list <- list()
  
  # Check all possible pairwise comparisons
  for(pair in sample_pairs) {
    s1 <- pair[1]
    s2 <- pair[2]
    
    filename <- paste0(s1, "_vs_", s2, "_", cluster, "_peaks.csv")
    if(file.exists(filename)) {
      df <- read.csv(filename, row.names = 1)
      df$Comparison <- paste0(s1, "_vs_", s2)
      cluster_data_list[[paste0(s1, s2)]] <- df
    }
  }
  
  # Combine if data exists
  if(length(cluster_data_list) > 0) {
    combined_df <- do.call(rbind, cluster_data_list)
    write.csv(combined_df, 
              file = paste0(cluster, "_all_peak_comparisons_combined.csv"), 
              row.names = TRUE)
    print(paste("  Combined", length(cluster_data_list), "comparisons with", 
                nrow(combined_df), "total peaks"))
  } else {
    print(paste("  No comparison files found for", cluster))
  }
}

###############################################
## 7. SUMMARY STATISTICS
###############################################

# Create summary table
summary_data <- data.frame(
  Comparison = character(),
  Cluster = character(),
  nPeaks = integer(),
  nUpregulated = integer(),
  nDownregulated = integer(),
  meanLog2FC_up = numeric(),
  meanLog2FC_down = numeric(),
  stringsAsFactors = FALSE
)

for(cluster in all_clusters) {
  for(pair in sample_pairs) {
    s1 <- pair[1]
    s2 <- pair[2]
    filename <- paste0(s1, "_vs_", s2, "_", cluster, "_peaks.csv")
    
    if(file.exists(filename)) {
      df <- read.csv(filename, row.names = 1)
      up_peaks <- df$Log2FC > 0
      down_peaks <- df$Log2FC < 0
      
      summary_data <- rbind(summary_data, data.frame(
        Comparison = paste0(s1, "_vs_", s2),
        Cluster = cluster,
        nPeaks = nrow(df),
        nUpregulated = sum(up_peaks),
        nDownregulated = sum(down_peaks),
        meanLog2FC_up = ifelse(sum(up_peaks) > 0, mean(df$Log2FC[up_peaks]), NA),
        meanLog2FC_down = ifelse(sum(down_peaks) > 0, mean(df$Log2FC[down_peaks]), NA)
      ))
    }
  }
}

# Save and display summary
write.csv(summary_data, "Peak_Analysis_Summary_by_Cluster_2025-10-09.csv", row.names = FALSE)
print("\n=== Summary of Differential Peaks ===")
print(summary_data)

# Create summary visualization
if(nrow(summary_data) > 0) {
  
  # Bar plot of peak counts
  p_summary <- ggplot(summary_data, aes(x = Cluster, y = nPeaks, fill = Comparison)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(
      title = "Differential Peaks by Cluster and Comparison",
      y = "Number of Significant Peaks",
      x = "Cluster"
    ) +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "right"
    ) +
    scale_fill_viridis_d()
  
  ggsave("Peak_Summary_BarPlot_by_Cluster_2025-10-09.pdf", p_summary, width = 14, height = 6)
  
  # Stacked bar plot showing up vs down
  summary_long <- summary_data %>%
    tidyr::pivot_longer(cols = c(nUpregulated, nDownregulated),
                        names_to = "Direction",
                        values_to = "Count") %>%
    mutate(Direction = ifelse(Direction == "nUpregulated", "Upregulated", "Downregulated"))
  
  p_direction <- ggplot(summary_long, aes(x = Cluster, y = Count, fill = Direction)) +
    geom_bar(stat = "identity", position = "stack") +
    facet_wrap(~Comparison, ncol = 3) +
    labs(
      title = "Direction of Peak Changes by Cluster",
      y = "Number of Peaks",
      x = "Cluster"
    ) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_fill_manual(values = c("Upregulated" = "#D62728", "Downregulated" = "#1F77B4"))
  
  ggsave("Peak_Direction_by_Cluster_2025-10-09.pdf", p_direction, width = 16, height = 10)
}

# Clusters with most differential peaks
if(nrow(summary_data) > 0) {
  top_clusters <- summary_data %>%
    group_by(Cluster) %>%
    summarise(TotalPeaks = sum(nPeaks)) %>%
    arrange(desc(TotalPeaks))
  
  print("\n=== Clusters with Most Differential Peaks ===")
  print(top_clusters)
  write.csv(top_clusters, "Top_Clusters_by_Peak_Count_2025-10-09.csv", row.names = FALSE)
}

###############################################
## 8. PEAK HEATMAPS BY CLUSTER (Optional)
###############################################

# Create heatmaps for clusters with many differential peaks
create_peak_heatmap <- function(cluster_name, min_peaks = 20) {
  
  combined_file <- paste0(cluster_name, "_all_peak_comparisons_combined.csv")
  if(!file.exists(combined_file)) return(NULL)
  
  df <- read.csv(combined_file, row.names = 1)
  if(nrow(df) < min_peaks) return(NULL)
  
  print(paste("Creating heatmap for", cluster_name, "with", nrow(df), "peaks"))
  
  # Get top peaks by FDR
  top_peaks <- df %>%
    arrange(FDR) %>%
    head(50)  # Top 50 peaks
  
  # Create a matrix of Log2FC values
  peak_matrix <- top_peaks %>%
    select(Comparison, Log2FC) %>%
    tidyr::pivot_wider(names_from = Comparison, values_from = Log2FC, values_fill = 0) %>%
    as.data.frame()
  
  # This is a simplified version - for full heatmap you'd need the actual peak matrix
  # Saving the data for external visualization
  write.csv(top_peaks, 
            paste0(cluster_name, "_top50_peaks_for_heatmap.csv"),
            row.names = TRUE)
  
  return(top_peaks)
}

# Generate heatmap data for clusters with sufficient peaks
for(cluster in all_clusters) {
  create_peak_heatmap(cluster, min_peaks = 20)
}

###############################################
## 9. EXPORT PEAK COORDINATES FOR IGV/UCSC
###############################################

# Export significant peaks in BED format for genome browser visualization
export_peaks_to_bed <- function(cluster_name) {
  
  combined_file <- paste0(cluster_name, "_all_peak_comparisons_combined.csv")
  if(!file.exists(combined_file)) return(NULL)
  
  df <- read.csv(combined_file, row.names = 1)
  if(nrow(df) == 0) return(NULL)
  
  # Create BED file
  bed_df <- data.frame(
    chrom = df$seqnames,
    chromStart = df$start,
    chromEnd = df$end,
    name = paste0(cluster_name, "_peak_", 1:nrow(df)),
    score = -log10(df$FDR),  # Use -log10(FDR) as score
    strand = "."
  )
  
  bed_file <- paste0(cluster_name, "_differential_peaks.bed")
  write.table(bed_df, bed_file, sep = "\t", quote = FALSE, 
              row.names = FALSE, col.names = FALSE)
  
  print(paste("Exported", nrow(bed_df), "peaks to", bed_file))
}

# Export BED files for all clusters
for(cluster in all_clusters) {
  export_peaks_to_bed(cluster)
}

###############################################
## 10. SAVE PROJECT
###############################################

saveArchRProject(ArchRProj = projP_3, 
                 outputDirectory = "/Volumes/DataBox2/Save-ProjP_3", 
                 load = FALSE)

